{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should never clean data manually, you should use code to automate cleaning tasks and minimize repetition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programmatic data cleaning has 3 steps:\n",
    "- Define\n",
    "- Code\n",
    "- Test\n",
    "\n",
    "The very first thing to do before any cleaning occurs is to make a copy of each piece of data. All of the cleaning operations will be conducted on this copy so you can still view the original dirty and/or messy dataset later. Copying DataFrames in pandas is done using the `copy` method. If the original DataFrame was called df, the soon-to-be clean copy of the dataset could be named df_clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "patients = pd.read_csv('patients.csv')\n",
    "treatments = pd.read_csv('treatments.csv')\n",
    "adverse_reactions = pd.read_csv('adverse_reactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean = patients.copy()\n",
    "treatments_clean = treatments.copy()\n",
    "adverse_reactions_clean = adverse_reactions.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "\n",
    "#### patients table\n",
    "\n",
    "- zip code is a float not a string\n",
    "- zip code has four gigits sometimes\n",
    "- Tim Neudorf height is 27 inches instead of 72 inches\n",
    "- State has some data in full name, some in abbreviations\n",
    "- Dsvid Gustafsson\n",
    "- Missing demographic information (address to contract)\n",
    "- Erroneous datetype (assigned sex(should be categrocal datatype), state, zip_code, birthdate)\n",
    "- multiple phone number formate\n",
    "- Default John Doe data\n",
    "- Multiple records for Jackbsen, Gersten, Taylor\n",
    "- kgs instrad of lbs for Zaitseva weight\n",
    "\n",
    "#### treatment table\n",
    "\n",
    "- missing HbA1c changes\n",
    "- the letter 'u' in starting and ending doese for auralin and novovrda\n",
    "- lowercase given names and surnames\n",
    "- missing records (280 instead of 350)\n",
    "- Erroneous datetype (auralin and novodra columns)\n",
    "- Inaccurate HbA1c_changes (4s mistaken as 9s)\n",
    "- Nulls represented as dashes (-) in auralin and novodra columns\n",
    "\n",
    "#### adverse_reactions table\n",
    "\n",
    "- lowercase given names and surnames\n",
    "\n",
    "### Tidiness\n",
    "\n",
    "- contact column in `patients` table should be split into phone number and email address\n",
    "- three variables in two columns in treatments table(treatment, start does and end does)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean\n",
    "\n",
    "### Missing Data\n",
    "\n",
    "- missing HbA1c changes\n",
    "- missing records (280 instead of 350)\n",
    "- Missing demographic information (address to contract): _there is no idea to deal with this information missing, for we do not have any contact information, maybe we could skim the phone book or the internet for their contact information, but it's more efficient to hold on until they come back to our office._\n",
    "\n",
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Knowledge: Imputation (statistics)](https://en.wikipedia.org/wiki/Imputation_(statistics))\n",
    "\n",
    "In statistics, imputation is the process of replacing missing data with substituted values. When substituting for a data point, it is known as \"unit imputation\"; when substituting for a component of a data point, it is known as \"item imputation\". There are three main problems that missing data causes: missing data can introduce a substantial amount of bias, make the handling and analysis of the data more arduous, and create reductions in efficiency.[1] Because missing data can create problems for analyzing data, imputation is seen as a way to avoid pitfalls involved with listwise deletion of cases that have missing values. That is to say, when one or more values are missing for a case, most statistical packages default to discarding any case that has a missing value, which may introduce bias or affect the representativeness of the results. Imputation preserves all cases by replacing missing data with an estimated value based on other available information. Once all missing values have been imputed, the data set can then be analysed using standard techniques for complete data.[2] Imputation theory is constantly developing and thus requires consistent attention to new information regarding the subject. There have been many theories embraced by scientists to account for missing data but the majority of them introduce large amounts of bias. A few of the well known attempts to deal with missing data include: hot deck and cold deck imputation; listwise and pairwise deletion; mean imputation; regression imputation; last observation carried forward; stochastic imputation; and multiple imputation.\n",
    "\n",
    "##### 1. Listwise (complete case) deletion\n",
    "By far, the most common means of dealing with missing data is listwise deletion (also known as complete case), which is when all cases with a missing value are deleted. If the data are missing completely at random, then listwise deletion does not add any bias, but it does decrease the power of the analysis by decreasing the effective sample size. For example, if 1000 cases are collected but 80 have missing values, the effective sample size after listwise deletion is 920. If the cases are not missing completely at random, then listwise deletion will introduce bias because the sub-sample of cases represented by the missing data are not representative of the original sample (and if the original sample was itself a representative sample of a population, the complete cases are not representative of that population either). While listwise deletion is unbiased when the missing data is missing completely at random, this is rarely the case in actuality.[3]\n",
    "\n",
    "Pairwise deletion (or \"available case analysis\") involves deleting a case when it is missing a variable required for a particular analysis, but including that case in analyses for which all required variables are present. When pairwise deletion is used, the total N for analysis will not be consistent across parameter estimations. Because of the incomplete N values at some points in time, while still maintaining complete case comparison for other parameters, pairwise deletion can introduce impossible mathematical situations such as correlations that are over 100%.[4]\n",
    "\n",
    "The one advantage complete case has over other methods is that it is straightforward and easy to implement. This is a large reason why complete case is the most popular method of handling missing data in spite of the many disadvantages it has.\n",
    "\n",
    "##### 2. Single imputation\n",
    "###### a) Hot-deck\n",
    "A once-common method of imputation was hot-deck imputation where a missing value was imputed from a randomly selected similar record. The term \"hot deck\" dates back to the storage of data on punched cards, and indicates that the information donors come from the same dataset as the recipients. The stack of cards was \"hot\" because it was currently being processed.     \n",
    "One form of hot-deck imputation is called \"last observation carried forward\" (or LOCF for short), which involves sorting a dataset according to any of a number of variables, thus creating an ordered dataset. The technique then finds the first missing value and uses the cell value immediately prior to the data that are missing to impute the missing value. The process is repeated for the next cell with a missing value until all missing values have been imputed. In the common scenario in which the cases are repeated measurements of a variable for a person or other entity, this represents the belief that if a measurement is missing, the best guess is that it hasn't changed from the last time it was measured. This method is known to increase risk of increasing bias and potentially false conclusions. For this reason LOCF is not recommended for use.[5]\n",
    "\n",
    "###### b) Cold-deck\n",
    "Cold-deck imputation, by contrast, selects donors from another dataset. Due to advances in computer power, more sophisticated methods of imputation have generally superseded the original random and sorted hot deck imputation techniques.\n",
    "\n",
    "###### c) Mean substitution\n",
    "Another imputation technique involves replacing any missing value with the mean of that variable for all other cases, which has the benefit of not changing the sample mean for that variable. However, mean imputation attenuates any correlations involving the variable(s) that are imputed. This is because, in cases with imputation, there is guaranteed to be no relationship between the imputed variable and any other measured variables. Thus, mean imputation has some attractive properties for univariate analysis but becomes problematic for multivariate analysis.\n",
    "\n",
    "###### d) Regression\n",
    "Regression imputation has the opposite problem of mean imputation. A regression model is estimated to predict observed values of a variable based on other variables, and that model is then used to impute values in cases where the value of that variable is missing. In other words, available information for complete and incomplete cases is used to predict the value of a specific variable. Fitted values from the regression model are then used to impute the missing values. The problem is that the imputed data do not have an error term included in their estimation, thus the estimates fit perfectly along the regression line without any residual variance. This causes relationships to be over identified and suggest greater precision in the imputed values than is warranted. The regression model predicts the most likely value of missing data but does not supply uncertainty about that value.    \n",
    "Stochastic regression was a fairly successful attempt to correct the lack of an error term in regression imputation by adding the average regression variance to the regression imputations to introduce error. Stochastic regression shows much less bias than the above-mentioned techniques, but it still missed one thing – if data are imputed then intuitively one would think that more noise should be introduced to the problem than simple residual variance.[4]\n",
    "\n",
    "#####  3.Multiple imputation\n",
    "In order to deal with the problem of increased noise due to imputation, Rubin (1987)[citation needed] developed a method for averaging the outcomes across multiple imputed data sets to account for this. All multiple imputation methods follow three steps.\n",
    "\n",
    "- Imputation – Similar to single imputation, missing values are imputed. However, the imputed values are drawn m times from a distribution rather than just once. At the end of this step, there should be m completed datasets.\n",
    "- Analysis – Each of the m datasets is analyzed. At the end of this step there should be m analyses.\n",
    "- Pooling – The m results are consolidated into one result by calculating the mean, variance, and confidence interval of the variable of concern.[6][7][failed verification]\n",
    "Just as there are multiple methods of single imputation, there are multiple methods of multiple imputation as well. One advantage that multiple imputation has over the single imputation and complete case methods is that multiple imputation is flexible and can be used in a wide variety of scenarios. Multiple imputation can be used in cases where the data is missing completely at random, missing at random, and even when the data is missing not at random. However, the primary method of multiple imputation is multiple imputation by chained equations (MICE). It is also known as \"fully conditional specification\" and, \"sequential regression multiple imputation.\" [8] MICE has been show to work very well on missing at random data, though there is evidence to suggest, through a simulation study, that with either a sufficient number of auxiliary variables it can also work on data that is missing not at random; use of a latent variable (derived through a Latent Class Analysis method produces more accurate estimates over MICE).[9]\n",
    "\n",
    "As alluded in the previous section, single imputation does not take into account the uncertainty in the imputations. After imputation, the data is treated as if they were the actual real values in single imputation. The negligence of uncertainty in the imputation can and will lead to overly precise results and errors in any conclusions drawn.[10] By imputing multiple times, multiple imputation certainly accounts for the uncertainty and range of values that the true value could have taken.\n",
    "\n",
    "Additionally, while it is the case that single imputation and complete case are easier to implement, multiple imputation is not very difficult to implement. There are a wide range of different statistical packages in different statistical software that readily allow someone to perform multiple imputation. For example, the MICE package allows users in R to perform multiple imputation using the MICE method.[11]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Complete the following two \"Missing Data\" **Define, Code, and Test** sequences after watching the *\"Address Missing Data First\"* video.</font>\n",
    "\n",
    "#### `treatments`: Missing records (280 instead of 350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Note: the missing `treatments` records are stored in a file named `treatments_cut.csv`*\n",
    "\n",
    "*concate the treatments dataset withe treatments_cut dataset, get a full dataset with 350 rows*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>auralin</th>\n",
       "      <th>novodra</th>\n",
       "      <th>hba1c_start</th>\n",
       "      <th>hba1c_end</th>\n",
       "      <th>hba1c_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jožka</td>\n",
       "      <td>resanovič</td>\n",
       "      <td>22u - 30u</td>\n",
       "      <td>-</td>\n",
       "      <td>7.56</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inunnguaq</td>\n",
       "      <td>heilmann</td>\n",
       "      <td>57u - 67u</td>\n",
       "      <td>-</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alwin</td>\n",
       "      <td>svensson</td>\n",
       "      <td>36u - 39u</td>\n",
       "      <td>-</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thể</td>\n",
       "      <td>lương</td>\n",
       "      <td>-</td>\n",
       "      <td>61u - 64u</td>\n",
       "      <td>7.64</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amanda</td>\n",
       "      <td>ribeiro</td>\n",
       "      <td>36u - 44u</td>\n",
       "      <td>-</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.47</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  given_name    surname    auralin    novodra  hba1c_start  hba1c_end  \\\n",
       "0      jožka  resanovič  22u - 30u          -         7.56       7.22   \n",
       "1  inunnguaq   heilmann  57u - 67u          -         7.85       7.45   \n",
       "2      alwin   svensson  36u - 39u          -         7.78       7.34   \n",
       "3        thể      lương          -  61u - 64u         7.64       7.22   \n",
       "4     amanda    ribeiro  36u - 44u          -         7.85       7.47   \n",
       "\n",
       "   hba1c_change  \n",
       "0          0.34  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3          0.92  \n",
       "4          0.38  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_cut = pd.read_csv('treatments_cut.csv')\n",
    "treatments_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70 entries, 0 to 69\n",
      "Data columns (total 7 columns):\n",
      "given_name      70 non-null object\n",
      "surname         70 non-null object\n",
      "auralin         70 non-null object\n",
      "novodra         70 non-null object\n",
      "hba1c_start     70 non-null float64\n",
      "hba1c_end       70 non-null float64\n",
      "hba1c_change    42 non-null float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "treatments_cut.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>auralin</th>\n",
       "      <th>novodra</th>\n",
       "      <th>hba1c_start</th>\n",
       "      <th>hba1c_end</th>\n",
       "      <th>hba1c_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>veronika</td>\n",
       "      <td>jindrová</td>\n",
       "      <td>41u - 48u</td>\n",
       "      <td>-</td>\n",
       "      <td>7.63</td>\n",
       "      <td>7.20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elliot</td>\n",
       "      <td>richardson</td>\n",
       "      <td>-</td>\n",
       "      <td>40u - 45u</td>\n",
       "      <td>7.56</td>\n",
       "      <td>7.09</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yukitaka</td>\n",
       "      <td>takenaka</td>\n",
       "      <td>-</td>\n",
       "      <td>39u - 36u</td>\n",
       "      <td>7.68</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skye</td>\n",
       "      <td>gormanston</td>\n",
       "      <td>33u - 36u</td>\n",
       "      <td>-</td>\n",
       "      <td>7.97</td>\n",
       "      <td>7.62</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alissa</td>\n",
       "      <td>montez</td>\n",
       "      <td>-</td>\n",
       "      <td>33u - 29u</td>\n",
       "      <td>7.78</td>\n",
       "      <td>7.46</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  given_name     surname    auralin    novodra  hba1c_start  hba1c_end  \\\n",
       "0   veronika    jindrová  41u - 48u          -         7.63       7.20   \n",
       "1     elliot  richardson          -  40u - 45u         7.56       7.09   \n",
       "2   yukitaka    takenaka          -  39u - 36u         7.68       7.25   \n",
       "3       skye  gormanston  33u - 36u          -         7.97       7.62   \n",
       "4     alissa      montez          -  33u - 29u         7.78       7.46   \n",
       "\n",
       "   hba1c_change  \n",
       "0           NaN  \n",
       "1          0.97  \n",
       "2           NaN  \n",
       "3          0.35  \n",
       "4          0.32  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 280 entries, 0 to 279\n",
      "Data columns (total 7 columns):\n",
      "given_name      280 non-null object\n",
      "surname         280 non-null object\n",
      "auralin         280 non-null object\n",
      "novodra         280 non-null object\n",
      "hba1c_start     280 non-null float64\n",
      "hba1c_end       280 non-null float64\n",
      "hba1c_change    171 non-null float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 15.4+ KB\n"
     ]
    }
   ],
   "source": [
    "treatments_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean = pd.concat([treatments,treatments_cut],\n",
    "                             ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 7)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `treatments`: Missing HbA1c changes and Inaccurate HbA1c changes (leading 4s mistaken as 9s)\n",
    "*Note: the \"Inaccurate HbA1c changes (leading 4s mistaken as 9s)\" observation, which is an accuracy issue and not a completeness issue, is included in this header because it is also fixed by the cleaning operation that fixes the missing \"Missing HbA1c changes\" observation. Multiple observations in one **Define, Code, and Test** header occurs multiple times in this notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "inplace null and wrong number in hba1c_change column with hba1c_start-hba1c_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean.hba1c_change = treatments_clean.hba1c_start - treatments_clean.hba1c_end \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.43\n",
       "1    0.47\n",
       "2    0.43\n",
       "3    0.35\n",
       "4    0.32\n",
       "Name: hba1c_change, dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_clean.hba1c_change.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It is better to tidy the tidiness issues (stractual issues) first, after that, data quality cleaning will be much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contact column in `patients` table contains two variables: phone number and email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Hint 1: use regular expressions with pandas' [`str.extract` method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.extract.html). Here is an amazing [regex tutorial](https://regexone.com/). Hint 2: [various phone number regex patterns](https://stackoverflow.com/questions/16699007/regular-expression-to-match-standard-10-digit-phone-number). Hint 3: [email address regex pattern](http://emailregex.com/), which you might need to modify to distinguish the email from the phone number.*\n",
    "\n",
    "separate the contact column into phone_number and email using regular expressions and pandas' `str.extract` method.Drop the contact clolumn when done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean['phone_number'] = patients_clean.contact.str.extract(\n",
    "    '((\\+\\d{1,2}\\s)?\\(?\\d{3}\\)?[\\s\\-]\\d{3}[\\s\\-]\\d{4})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean['email']= patients_clean.contact.str.extract(\n",
    "    '([a-zA-Z]\\w*@\\w+\\.[A-Za-z]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean.drop(columns = {'contact'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 503 entries, 0 to 502\n",
      "Data columns (total 15 columns):\n",
      "patient_id      503 non-null int64\n",
      "assigned_sex    503 non-null object\n",
      "given_name      503 non-null object\n",
      "surname         503 non-null object\n",
      "address         491 non-null object\n",
      "city            491 non-null object\n",
      "state           491 non-null object\n",
      "zip_code        491 non-null float64\n",
      "country         491 non-null object\n",
      "birthdate       503 non-null object\n",
      "weight          503 non-null float64\n",
      "height          503 non-null int64\n",
      "bmi             503 non-null float64\n",
      "phone_number    485 non-null object\n",
      "email           491 non-null object\n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 59.1+ KB\n"
     ]
    }
   ],
   "source": [
    "patients_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           951-719-9170\n",
       "1      +1 (217) 569-3204\n",
       "2           402-363-6804\n",
       "3      +1 (732) 636-8246\n",
       "4           334-515-7487\n",
       "             ...        \n",
       "498         207-477-0579\n",
       "499         928-284-4492\n",
       "500         816-223-6007\n",
       "501         360 443 2060\n",
       "502         402-848-4923\n",
       "Name: phone_number, Length: 503, dtype: object"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean.phone_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               ZoeWellish@superrito.com\n",
       "1                   PamelaSHill@cuvox.de\n",
       "2                   JaeMDebord@gustr.com\n",
       "3              PhanBaLiem@jourrapide.com\n",
       "4                    TimNeudorf@cuvox.de\n",
       "                     ...                \n",
       "498      MustafaLindstrom@jourrapide.com\n",
       "499               RumanBisliev@gustr.com\n",
       "500            JinkedeKeizer@teleworm.us\n",
       "501    ChidaluOnyekaozulu@jourrapide.com\n",
       "502             PatrickGersten@rhyta.com\n",
       "Name: email, Length: 503, dtype: object"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean.email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>assigned_sex</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>bmi</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>female</td>\n",
       "      <td>Lalita</td>\n",
       "      <td>Eldarkhanov</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/14/1950</td>\n",
       "      <td>143.4</td>\n",
       "      <td>62</td>\n",
       "      <td>26.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>220</td>\n",
       "      <td>male</td>\n",
       "      <td>Mỹ</td>\n",
       "      <td>Quynh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/9/1978</td>\n",
       "      <td>237.8</td>\n",
       "      <td>69</td>\n",
       "      <td>35.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>231</td>\n",
       "      <td>female</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Knudsen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/23/1976</td>\n",
       "      <td>165.9</td>\n",
       "      <td>63</td>\n",
       "      <td>29.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>235</td>\n",
       "      <td>female</td>\n",
       "      <td>Martina</td>\n",
       "      <td>Tománková</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/7/1936</td>\n",
       "      <td>199.5</td>\n",
       "      <td>65</td>\n",
       "      <td>33.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>243</td>\n",
       "      <td>male</td>\n",
       "      <td>John</td>\n",
       "      <td>O'Brian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/25/1957</td>\n",
       "      <td>205.3</td>\n",
       "      <td>74</td>\n",
       "      <td>26.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250</td>\n",
       "      <td>male</td>\n",
       "      <td>Benjamin</td>\n",
       "      <td>Mehler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/30/1951</td>\n",
       "      <td>146.5</td>\n",
       "      <td>69</td>\n",
       "      <td>21.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>258</td>\n",
       "      <td>male</td>\n",
       "      <td>Jin</td>\n",
       "      <td>Kung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/17/1995</td>\n",
       "      <td>231.7</td>\n",
       "      <td>69</td>\n",
       "      <td>34.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>265</td>\n",
       "      <td>female</td>\n",
       "      <td>Wafiyyah</td>\n",
       "      <td>Asfour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/3/1989</td>\n",
       "      <td>158.6</td>\n",
       "      <td>63</td>\n",
       "      <td>28.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>270</td>\n",
       "      <td>female</td>\n",
       "      <td>Flavia</td>\n",
       "      <td>Fiorentino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/9/1937</td>\n",
       "      <td>175.2</td>\n",
       "      <td>61</td>\n",
       "      <td>33.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>279</td>\n",
       "      <td>female</td>\n",
       "      <td>Generosa</td>\n",
       "      <td>Cabán</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/16/1962</td>\n",
       "      <td>124.3</td>\n",
       "      <td>69</td>\n",
       "      <td>18.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>287</td>\n",
       "      <td>male</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>Webb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/1/1979</td>\n",
       "      <td>155.3</td>\n",
       "      <td>68</td>\n",
       "      <td>23.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>297</td>\n",
       "      <td>female</td>\n",
       "      <td>Chỉ</td>\n",
       "      <td>Lâm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/14/1990</td>\n",
       "      <td>181.1</td>\n",
       "      <td>63</td>\n",
       "      <td>32.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id assigned_sex given_name      surname address city state  \\\n",
       "209         210       female     Lalita  Eldarkhanov     NaN  NaN   NaN   \n",
       "219         220         male         Mỹ        Quynh     NaN  NaN   NaN   \n",
       "230         231       female  Elisabeth      Knudsen     NaN  NaN   NaN   \n",
       "234         235       female    Martina    Tománková     NaN  NaN   NaN   \n",
       "242         243         male       John      O'Brian     NaN  NaN   NaN   \n",
       "249         250         male   Benjamin       Mehler     NaN  NaN   NaN   \n",
       "257         258         male        Jin         Kung     NaN  NaN   NaN   \n",
       "264         265       female   Wafiyyah       Asfour     NaN  NaN   NaN   \n",
       "269         270       female     Flavia   Fiorentino     NaN  NaN   NaN   \n",
       "278         279       female   Generosa        Cabán     NaN  NaN   NaN   \n",
       "286         287         male      Lewis         Webb     NaN  NaN   NaN   \n",
       "296         297       female        Chỉ          Lâm     NaN  NaN   NaN   \n",
       "\n",
       "     zip_code country   birthdate  weight  height   bmi phone_number email  \n",
       "209       NaN     NaN   8/14/1950   143.4      62  26.2          NaN   NaN  \n",
       "219       NaN     NaN    4/9/1978   237.8      69  35.1          NaN   NaN  \n",
       "230       NaN     NaN   9/23/1976   165.9      63  29.4          NaN   NaN  \n",
       "234       NaN     NaN    4/7/1936   199.5      65  33.2          NaN   NaN  \n",
       "242       NaN     NaN   2/25/1957   205.3      74  26.4          NaN   NaN  \n",
       "249       NaN     NaN  10/30/1951   146.5      69  21.6          NaN   NaN  \n",
       "257       NaN     NaN   5/17/1995   231.7      69  34.2          NaN   NaN  \n",
       "264       NaN     NaN   11/3/1989   158.6      63  28.1          NaN   NaN  \n",
       "269       NaN     NaN   10/9/1937   175.2      61  33.1          NaN   NaN  \n",
       "278       NaN     NaN  12/16/1962   124.3      69  18.4          NaN   NaN  \n",
       "286       NaN     NaN    4/1/1979   155.3      68  23.6          NaN   NaN  \n",
       "296       NaN     NaN   5/14/1990   181.1      63  32.1          NaN   NaN  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean[patients_clean.email.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three variables in two columns in `treatments` table (treatment, start dose and end dose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: use pandas' [melt function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html) and [`str.split()` method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.split.html). Here is an excellent [`melt` tutorial](https://deparkes.co.uk/2016/10/28/reshape-pandas-data-with-melt/).*\n",
    "\n",
    "use pandas.melt to change auralin and novodra into two columns,one is method, one is dose. Then split the dose column on '-' to obtain 'start_dose' and  'end_dose' columns. Drop the intermediate dose column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "treatments_clean = pd.melt(treatments_clean, id_vars=['given_name', 'surname', 'hba1c_start', 'hba1c_end', 'hba1c_change'],\n",
    "                           var_name='treatment', value_name='dose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean = treatments_clean[treatments_clean.dose != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean[['dose_start','dose_end']] = treatments_clean['dose'].str.split(' - ',expand = True)\n",
    "#treatments_clean['dose_start'], treatments_clean['dose_end'] = treatments_clean['dose'].str.split(' - ', 1).str\n",
    "# because The pandas.Series.str accessor can be assigned to the columns. https://stackoverflow.com/questions/57463127/splitting-a-column-in-dataframe-using-str-split-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean.drop(columns = {'dose'},inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>hba1c_start</th>\n",
       "      <th>hba1c_end</th>\n",
       "      <th>hba1c_change</th>\n",
       "      <th>treatment</th>\n",
       "      <th>dose_start</th>\n",
       "      <th>dose_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>veronika</td>\n",
       "      <td>jindrová</td>\n",
       "      <td>7.63</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>auralin</td>\n",
       "      <td>41u</td>\n",
       "      <td>48u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>skye</td>\n",
       "      <td>gormanston</td>\n",
       "      <td>7.97</td>\n",
       "      <td>7.62</td>\n",
       "      <td>0.35</td>\n",
       "      <td>auralin</td>\n",
       "      <td>33u</td>\n",
       "      <td>36u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sophia</td>\n",
       "      <td>haugen</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>auralin</td>\n",
       "      <td>37u</td>\n",
       "      <td>42u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eddie</td>\n",
       "      <td>archer</td>\n",
       "      <td>7.89</td>\n",
       "      <td>7.55</td>\n",
       "      <td>0.34</td>\n",
       "      <td>auralin</td>\n",
       "      <td>31u</td>\n",
       "      <td>38u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>asia</td>\n",
       "      <td>woźniak</td>\n",
       "      <td>7.76</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>auralin</td>\n",
       "      <td>30u</td>\n",
       "      <td>36u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  given_name     surname  hba1c_start  hba1c_end  hba1c_change treatment  \\\n",
       "0   veronika    jindrová         7.63       7.20          0.43   auralin   \n",
       "3       skye  gormanston         7.97       7.62          0.35   auralin   \n",
       "6     sophia      haugen         7.65       7.27          0.38   auralin   \n",
       "7      eddie      archer         7.89       7.55          0.34   auralin   \n",
       "9       asia     woźniak         7.76       7.37          0.39   auralin   \n",
       "\n",
       "  dose_start dose_end  \n",
       "0        41u      48u  \n",
       "3        33u      36u  \n",
       "6        37u      42u  \n",
       "7        31u      38u  \n",
       "9        30u      36u  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adverse reaction should be part of the `treatments` table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: [tutorial](https://chrisalbon.com/python/pandas_join_merge_dataframe.html) for the function used in the solution.*\n",
    "\n",
    "merge adverse_reactions_clean's adverse_reaction column to treatments_clean, using pandas' merge function, and use left join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean = pd.merge(treatments_clean,adverse_reactions_clean,on = ['given_name','surname'],how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 9)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>hba1c_start</th>\n",
       "      <th>hba1c_end</th>\n",
       "      <th>hba1c_change</th>\n",
       "      <th>treatment</th>\n",
       "      <th>dose_start</th>\n",
       "      <th>dose_end</th>\n",
       "      <th>adverse_reaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>veronika</td>\n",
       "      <td>jindrová</td>\n",
       "      <td>7.63</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>auralin</td>\n",
       "      <td>41u</td>\n",
       "      <td>48u</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skye</td>\n",
       "      <td>gormanston</td>\n",
       "      <td>7.97</td>\n",
       "      <td>7.62</td>\n",
       "      <td>0.35</td>\n",
       "      <td>auralin</td>\n",
       "      <td>33u</td>\n",
       "      <td>36u</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sophia</td>\n",
       "      <td>haugen</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>auralin</td>\n",
       "      <td>37u</td>\n",
       "      <td>42u</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eddie</td>\n",
       "      <td>archer</td>\n",
       "      <td>7.89</td>\n",
       "      <td>7.55</td>\n",
       "      <td>0.34</td>\n",
       "      <td>auralin</td>\n",
       "      <td>31u</td>\n",
       "      <td>38u</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asia</td>\n",
       "      <td>woźniak</td>\n",
       "      <td>7.76</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>auralin</td>\n",
       "      <td>30u</td>\n",
       "      <td>36u</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  given_name     surname  hba1c_start  hba1c_end  hba1c_change treatment  \\\n",
       "0   veronika    jindrová         7.63       7.20          0.43   auralin   \n",
       "1       skye  gormanston         7.97       7.62          0.35   auralin   \n",
       "2     sophia      haugen         7.65       7.27          0.38   auralin   \n",
       "3      eddie      archer         7.89       7.55          0.34   auralin   \n",
       "4       asia     woźniak         7.76       7.37          0.39   auralin   \n",
       "\n",
       "  dose_start dose_end adverse_reaction  \n",
       "0        41u      48u              NaN  \n",
       "1        33u      36u              NaN  \n",
       "2        37u      42u              NaN  \n",
       "3        31u      38u              NaN  \n",
       "4        30u      36u              NaN  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_clean.adverse_reaction.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 3)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adverse_reactions_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_clean.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given name and surname columns in `patients` table duplicated in `treatments` and `adverse_reactions` tables  and Lowercase given names and surnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: [tutorial](https://chrisalbon.com/python/pandas_join_merge_dataframe.html) for one function used in the solution and [tutorial](http://erikrood.com/Python_References/dropping_rows_cols_pandas.html) for another function used in the solution.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean.given_name = treatments_clean.given_name.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean.surname = treatments_clean.surname.str.capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean = pd.merge(treatments_clean,patients_clean[['patient_id','given_name','surname']], on = ['given_name','surname'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatments_clean.drop(columns = {'given_name','surname'},inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hba1c_start</th>\n",
       "      <th>hba1c_end</th>\n",
       "      <th>hba1c_change</th>\n",
       "      <th>treatment</th>\n",
       "      <th>dose_start</th>\n",
       "      <th>dose_end</th>\n",
       "      <th>adverse_reaction</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.63</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.43</td>\n",
       "      <td>auralin</td>\n",
       "      <td>41u</td>\n",
       "      <td>48u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.97</td>\n",
       "      <td>7.62</td>\n",
       "      <td>0.35</td>\n",
       "      <td>auralin</td>\n",
       "      <td>33u</td>\n",
       "      <td>36u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.65</td>\n",
       "      <td>7.27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>auralin</td>\n",
       "      <td>37u</td>\n",
       "      <td>42u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.89</td>\n",
       "      <td>7.55</td>\n",
       "      <td>0.34</td>\n",
       "      <td>auralin</td>\n",
       "      <td>31u</td>\n",
       "      <td>38u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.76</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>auralin</td>\n",
       "      <td>30u</td>\n",
       "      <td>36u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>7.51</td>\n",
       "      <td>7.06</td>\n",
       "      <td>0.45</td>\n",
       "      <td>novodra</td>\n",
       "      <td>55u</td>\n",
       "      <td>51u</td>\n",
       "      <td>nausea</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>7.67</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>novodra</td>\n",
       "      <td>26u</td>\n",
       "      <td>23u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>9.21</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>novodra</td>\n",
       "      <td>22u</td>\n",
       "      <td>23u</td>\n",
       "      <td>injection site discomfort</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>7.96</td>\n",
       "      <td>7.51</td>\n",
       "      <td>0.45</td>\n",
       "      <td>novodra</td>\n",
       "      <td>28u</td>\n",
       "      <td>26u</td>\n",
       "      <td>hypoglycemia</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>7.68</td>\n",
       "      <td>7.21</td>\n",
       "      <td>0.47</td>\n",
       "      <td>novodra</td>\n",
       "      <td>42u</td>\n",
       "      <td>44u</td>\n",
       "      <td>injection site discomfort</td>\n",
       "      <td>477.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hba1c_start  hba1c_end  hba1c_change treatment dose_start dose_end  \\\n",
       "0           7.63       7.20          0.43   auralin       41u       48u   \n",
       "1           7.97       7.62          0.35   auralin       33u       36u   \n",
       "2           7.65       7.27          0.38   auralin       37u       42u   \n",
       "3           7.89       7.55          0.34   auralin       31u       38u   \n",
       "4           7.76       7.37          0.39   auralin       30u       36u   \n",
       "..           ...        ...           ...       ...        ...      ...   \n",
       "345         7.51       7.06          0.45   novodra       55u       51u   \n",
       "346         7.67       7.30          0.37   novodra       26u       23u   \n",
       "347         9.21       8.80          0.41   novodra       22u       23u   \n",
       "348         7.96       7.51          0.45   novodra       28u       26u   \n",
       "349         7.68       7.21          0.47   novodra       42u       44u   \n",
       "\n",
       "              adverse_reaction  patient_id  \n",
       "0                          NaN       225.0  \n",
       "1                          NaN       242.0  \n",
       "2                          NaN       345.0  \n",
       "3                          NaN       276.0  \n",
       "4                          NaN        15.0  \n",
       "..                         ...         ...  \n",
       "345                     nausea       153.0  \n",
       "346                        NaN       420.0  \n",
       "347  injection site discomfort       336.0  \n",
       "348               hypoglycemia        25.0  \n",
       "349  injection site discomfort       477.0  \n",
       "\n",
       "[350 rows x 8 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    patient_id\n",
       "dtype: object"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Patient ID should be the only duplicate column\n",
    "all_columns = pd.Series(list(patients_clean) + list(treatments_clean))\n",
    "all_columns[all_columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "<font color='red'>Complete the remaining \"Quality\" **Define, Code, and Test** sequences after watching the *\"Cleaning for Quality\"* video.</font>\n",
    "#### Zip code is a float not a string and Zip code has four digits sometimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: see the \"Data Cleaning Process\" page.*\n",
    "convert zip code column's datatype to string, get rid of the last two character (.0) ,if the string only have 5 characters, add a '0' at the begining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad strings in the Series/Index up to width.\n",
    "patients_clean.zip_code = patients_clean.zip_code.astype(str).str[:-2].str.pad(5,fillchar = '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      92390\n",
       "1      61812\n",
       "2      68467\n",
       "3      07095\n",
       "4      36303\n",
       "       ...  \n",
       "498    03852\n",
       "499    86341\n",
       "500    64110\n",
       "501    98109\n",
       "502    68324\n",
       "Name: zip_code, Length: 503, dtype: object"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean.zip_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tim Neudorf height is 27 in instead of 72 in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "change the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean.loc [4,'height'] = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>assigned_sex</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>bmi</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Zoe</td>\n",
       "      <td>Wellish</td>\n",
       "      <td>576 Brown Bear Drive</td>\n",
       "      <td>Rancho California</td>\n",
       "      <td>California</td>\n",
       "      <td>92390</td>\n",
       "      <td>United States</td>\n",
       "      <td>7/10/1976</td>\n",
       "      <td>121.7</td>\n",
       "      <td>66</td>\n",
       "      <td>19.6</td>\n",
       "      <td>951-719-9170</td>\n",
       "      <td>ZoeWellish@superrito.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>Pamela</td>\n",
       "      <td>Hill</td>\n",
       "      <td>2370 University Hill Road</td>\n",
       "      <td>Armstrong</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>61812</td>\n",
       "      <td>United States</td>\n",
       "      <td>4/3/1967</td>\n",
       "      <td>118.8</td>\n",
       "      <td>66</td>\n",
       "      <td>19.2</td>\n",
       "      <td>+1 (217) 569-3204</td>\n",
       "      <td>PamelaSHill@cuvox.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Jae</td>\n",
       "      <td>Debord</td>\n",
       "      <td>1493 Poling Farm Road</td>\n",
       "      <td>York</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>68467</td>\n",
       "      <td>United States</td>\n",
       "      <td>2/19/1980</td>\n",
       "      <td>177.8</td>\n",
       "      <td>71</td>\n",
       "      <td>24.8</td>\n",
       "      <td>402-363-6804</td>\n",
       "      <td>JaeMDebord@gustr.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>Liêm</td>\n",
       "      <td>Phan</td>\n",
       "      <td>2335 Webster Street</td>\n",
       "      <td>Woodbridge</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07095</td>\n",
       "      <td>United States</td>\n",
       "      <td>7/26/1951</td>\n",
       "      <td>220.9</td>\n",
       "      <td>70</td>\n",
       "      <td>31.7</td>\n",
       "      <td>+1 (732) 636-8246</td>\n",
       "      <td>PhanBaLiem@jourrapide.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Neudorf</td>\n",
       "      <td>1428 Turkey Pen Lane</td>\n",
       "      <td>Dothan</td>\n",
       "      <td>AL</td>\n",
       "      <td>36303</td>\n",
       "      <td>United States</td>\n",
       "      <td>2/18/1928</td>\n",
       "      <td>192.3</td>\n",
       "      <td>72</td>\n",
       "      <td>26.1</td>\n",
       "      <td>334-515-7487</td>\n",
       "      <td>TimNeudorf@cuvox.de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id assigned_sex given_name  surname                    address  \\\n",
       "0           1       female        Zoe  Wellish       576 Brown Bear Drive   \n",
       "1           2       female     Pamela     Hill  2370 University Hill Road   \n",
       "2           3         male        Jae   Debord      1493 Poling Farm Road   \n",
       "3           4         male       Liêm     Phan        2335 Webster Street   \n",
       "4           5         male        Tim  Neudorf       1428 Turkey Pen Lane   \n",
       "\n",
       "                city       state zip_code        country  birthdate  weight  \\\n",
       "0  Rancho California  California    92390  United States  7/10/1976   121.7   \n",
       "1          Armstrong    Illinois    61812  United States   4/3/1967   118.8   \n",
       "2               York    Nebraska    68467  United States  2/19/1980   177.8   \n",
       "3         Woodbridge          NJ    07095  United States  7/26/1951   220.9   \n",
       "4             Dothan          AL    36303  United States  2/18/1928   192.3   \n",
       "\n",
       "   height   bmi       phone_number                      email  \n",
       "0      66  19.6       951-719-9170   ZoeWellish@superrito.com  \n",
       "1      66  19.2  +1 (217) 569-3204       PamelaSHill@cuvox.de  \n",
       "2      71  24.8       402-363-6804       JaeMDebord@gustr.com  \n",
       "3      70  31.7  +1 (732) 636-8246  PhanBaLiem@jourrapide.com  \n",
       "4      72  26.1       334-515-7487        TimNeudorf@cuvox.de  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full state names sometimes, abbreviations other times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "*Your definition here. Hint: [tutorial](https://chrisalbon.com/python/pandas_apply_operations_to_dataframes.html) for method used in solution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California    36\n",
       "TX            32\n",
       "New York      25\n",
       "CA            24\n",
       "MA            22\n",
       "NY            22\n",
       "PA            18\n",
       "GA            15\n",
       "Illinois      14\n",
       "OH            14\n",
       "Florida       13\n",
       "MI            13\n",
       "LA            13\n",
       "OK            13\n",
       "NJ            12\n",
       "VA            11\n",
       "IL            10\n",
       "WI            10\n",
       "MS            10\n",
       "TN             9\n",
       "AL             9\n",
       "IN             9\n",
       "FL             9\n",
       "MN             9\n",
       "WA             8\n",
       "KY             8\n",
       "NC             8\n",
       "MO             7\n",
       "KS             6\n",
       "NV             6\n",
       "ID             6\n",
       "IA             5\n",
       "SC             5\n",
       "CT             5\n",
       "AR             4\n",
       "ND             4\n",
       "Nebraska       4\n",
       "AZ             4\n",
       "CO             4\n",
       "ME             4\n",
       "RI             4\n",
       "SD             3\n",
       "MD             3\n",
       "WV             3\n",
       "OR             3\n",
       "DE             3\n",
       "DC             2\n",
       "NE             2\n",
       "VT             2\n",
       "MT             2\n",
       "NM             1\n",
       "AK             1\n",
       "NH             1\n",
       "WY             1\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'California':'CA','New York':'NY','Illinois':'IL','Florida':'FL','Nebraska':'NE'}\n",
    "\n",
    "def abbreviations(state):\n",
    "    if state in dic:\n",
    "        return dic[state]\n",
    "    else:\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean.state = patients_clean.state.apply(abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA    60\n",
       "NY    47\n",
       "TX    32\n",
       "IL    24\n",
       "MA    22\n",
       "FL    22\n",
       "PA    18\n",
       "GA    15\n",
       "OH    14\n",
       "LA    13\n",
       "OK    13\n",
       "MI    13\n",
       "NJ    12\n",
       "VA    11\n",
       "MS    10\n",
       "WI    10\n",
       "MN     9\n",
       "TN     9\n",
       "IN     9\n",
       "AL     9\n",
       "WA     8\n",
       "NC     8\n",
       "KY     8\n",
       "MO     7\n",
       "NE     6\n",
       "NV     6\n",
       "KS     6\n",
       "ID     6\n",
       "CT     5\n",
       "SC     5\n",
       "IA     5\n",
       "RI     4\n",
       "AZ     4\n",
       "AR     4\n",
       "ND     4\n",
       "CO     4\n",
       "ME     4\n",
       "SD     3\n",
       "MD     3\n",
       "OR     3\n",
       "DE     3\n",
       "WV     3\n",
       "MT     2\n",
       "VT     2\n",
       "DC     2\n",
       "NH     1\n",
       "NM     1\n",
       "AK     1\n",
       "WY     1\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dsvid Gustafsson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define\n",
    "correct Dsvid to David"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>assigned_sex</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>bmi</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>male</td>\n",
       "      <td>Dsvid</td>\n",
       "      <td>Gustafsson</td>\n",
       "      <td>1790 Nutter Street</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>MO</td>\n",
       "      <td>64105</td>\n",
       "      <td>United States</td>\n",
       "      <td>3/6/1937</td>\n",
       "      <td>163.9</td>\n",
       "      <td>66</td>\n",
       "      <td>26.5</td>\n",
       "      <td>816-265-9578</td>\n",
       "      <td>DavidGustafsson@armyspy.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id assigned_sex given_name     surname             address  \\\n",
       "8           9         male      Dsvid  Gustafsson  1790 Nutter Street   \n",
       "\n",
       "          city state zip_code        country birthdate  weight  height   bmi  \\\n",
       "8  Kansas City    MO    64105  United States  3/6/1937   163.9      66  26.5   \n",
       "\n",
       "   phone_number                        email  \n",
       "8  816-265-9578  DavidGustafsson@armyspy.com  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean[patients_clean.given_name == 'Dsvid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_clean.loc[8,'given_name'] = 'David'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David'"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean.loc[8,'given_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "^(?:(?:\\+?1\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|\n",
    "                             ([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?\n",
    "([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>assigned_sex</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>country</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>bmi</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Zoe</td>\n",
       "      <td>Wellish</td>\n",
       "      <td>576 Brown Bear Drive</td>\n",
       "      <td>Rancho California</td>\n",
       "      <td>CA</td>\n",
       "      <td>92390</td>\n",
       "      <td>United States</td>\n",
       "      <td>7/10/1976</td>\n",
       "      <td>121.7</td>\n",
       "      <td>66</td>\n",
       "      <td>19.6</td>\n",
       "      <td>951-719-9170</td>\n",
       "      <td>ZoeWellish@superrito.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>Pamela</td>\n",
       "      <td>Hill</td>\n",
       "      <td>2370 University Hill Road</td>\n",
       "      <td>Armstrong</td>\n",
       "      <td>IL</td>\n",
       "      <td>61812</td>\n",
       "      <td>United States</td>\n",
       "      <td>4/3/1967</td>\n",
       "      <td>118.8</td>\n",
       "      <td>66</td>\n",
       "      <td>19.2</td>\n",
       "      <td>+1 (217) 569-3204</td>\n",
       "      <td>PamelaSHill@cuvox.de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Jae</td>\n",
       "      <td>Debord</td>\n",
       "      <td>1493 Poling Farm Road</td>\n",
       "      <td>York</td>\n",
       "      <td>NE</td>\n",
       "      <td>68467</td>\n",
       "      <td>United States</td>\n",
       "      <td>2/19/1980</td>\n",
       "      <td>177.8</td>\n",
       "      <td>71</td>\n",
       "      <td>24.8</td>\n",
       "      <td>402-363-6804</td>\n",
       "      <td>JaeMDebord@gustr.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>Liêm</td>\n",
       "      <td>Phan</td>\n",
       "      <td>2335 Webster Street</td>\n",
       "      <td>Woodbridge</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07095</td>\n",
       "      <td>United States</td>\n",
       "      <td>7/26/1951</td>\n",
       "      <td>220.9</td>\n",
       "      <td>70</td>\n",
       "      <td>31.7</td>\n",
       "      <td>+1 (732) 636-8246</td>\n",
       "      <td>PhanBaLiem@jourrapide.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Neudorf</td>\n",
       "      <td>1428 Turkey Pen Lane</td>\n",
       "      <td>Dothan</td>\n",
       "      <td>AL</td>\n",
       "      <td>36303</td>\n",
       "      <td>United States</td>\n",
       "      <td>2/18/1928</td>\n",
       "      <td>192.3</td>\n",
       "      <td>72</td>\n",
       "      <td>26.1</td>\n",
       "      <td>334-515-7487</td>\n",
       "      <td>TimNeudorf@cuvox.de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id assigned_sex given_name  surname                    address  \\\n",
       "0           1       female        Zoe  Wellish       576 Brown Bear Drive   \n",
       "1           2       female     Pamela     Hill  2370 University Hill Road   \n",
       "2           3         male        Jae   Debord      1493 Poling Farm Road   \n",
       "3           4         male       Liêm     Phan        2335 Webster Street   \n",
       "4           5         male        Tim  Neudorf       1428 Turkey Pen Lane   \n",
       "\n",
       "                city state zip_code        country  birthdate  weight  height  \\\n",
       "0  Rancho California    CA    92390  United States  7/10/1976   121.7      66   \n",
       "1          Armstrong    IL    61812  United States   4/3/1967   118.8      66   \n",
       "2               York    NE    68467  United States  2/19/1980   177.8      71   \n",
       "3         Woodbridge    NJ    07095  United States  7/26/1951   220.9      70   \n",
       "4             Dothan    AL    36303  United States  2/18/1928   192.3      72   \n",
       "\n",
       "    bmi       phone_number                      email  \n",
       "0  19.6       951-719-9170   ZoeWellish@superrito.com  \n",
       "1  19.2  +1 (217) 569-3204       PamelaSHill@cuvox.de  \n",
       "2  24.8       402-363-6804       JaeMDebord@gustr.com  \n",
       "3  31.7  +1 (732) 636-8246  PhanBaLiem@jourrapide.com  \n",
       "4  26.1       334-515-7487        TimNeudorf@cuvox.de  "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_clean.phone_number.str.replace(r'\\D+', '').str.pad(11, fillchar='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
