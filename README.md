# Data-wrangling
This project is used for me to dive deeply into data wrangling. This is a coure from udacity's data analysis nanodegree program

## Introduction
Standard data wrangling process can be divied into 3 parts.

- Gathering data, in this step, I should try to get enough data, using web scraper
- Accessing data, in this step, I find what problems this dataset has
- cleaning and tiding data, in this step, I try every menthod to make the data ready for further analysing.
- saving data, in this step, I save the file as a csv file, or in a database.

## Tools I used
I used requests, API, pandas, numpy, matplotlib to do the analysis, and used jupyter notebook to run all the code.

## Process
I followed the project instraction step by step to gather, assess, clean, and save.

## License
This project is Hao Xu's Udacity Nanodegree project. The datasets and instractions are all from udacity.
